{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prakhar021-hub/Natural-Language-Processing/blob/main/NLP_word_count.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Built-in Function - Count Words"
      ],
      "metadata": {
        "id": "CmSTk4-d6AuH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk09A6wb58NU",
        "outputId": "e71eff77-e475-4178-d9d7-64a2a5d1d0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count: 8\n"
          ]
        }
      ],
      "source": [
        "text = \"Natural Language Processing (NLP) is a fascinating field!\"\n",
        "words = text.split()\n",
        "word_count = len(words)\n",
        "print(\"Word Count:\", word_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regex - Handle Punctuation and Count Words"
      ],
      "metadata": {
        "id": "nAj5AS976Ga_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def count_words(text):\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    return len(words)\n",
        "\n",
        "text = \"Hello, world! Welcome to NLP.\"\n",
        "print(\"Word Count:\", count_words(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gjcKi0N6Fs7",
        "outputId": "239ee6b4-6314-44bd-faf8-a5da87effa85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLTK - Python"
      ],
      "metadata": {
        "id": "O72Snbg76PX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh2vpvIG6WW5",
        "outputId": "a0a80f71-6003-4a68-82d7-11ab87427d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "def count_words_nltk(text):\n",
        "    words = word_tokenize(text)\n",
        "    return len(words)\n",
        "\n",
        "text = \"Let's explore NLP with Python!\"\n",
        "print(\"Word Count:\", count_words_nltk(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2yG15Ok6Mgo",
        "outputId": "eb155c6e-26ce-4a21-8d76-4aba61ebd898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy"
      ],
      "metadata": {
        "id": "N_r71oU56zOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def count_words_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    words = [token.text for token in doc if not token.is_punct]\n",
        "    return len(words)\n",
        "\n",
        "text = \"NLP is amazing, isn't it?\"\n",
        "print(\"Word Count:\", count_words_spacy(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5joBnb76QvQ",
        "outputId": "6bb2a57a-8384-483b-9f56-d75dc40ddc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Counter"
      ],
      "metadata": {
        "id": "44Opnq7V64a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def word_frequency(text):\n",
        "    words = text.lower().split()\n",
        "    return Counter(words)\n",
        "\n",
        "text = \"NLP is fun. NLP is powerful. NLP is the future.\"\n",
        "print(\"Word Frequencies:\", word_frequency(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNUrt7dZ60n8",
        "outputId": "1255e55d-744e-40fc-f86a-b09c6fc5e5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequencies: Counter({'nlp': 3, 'is': 3, 'fun.': 1, 'powerful.': 1, 'the': 1, 'future.': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP Task 1 - Short vs Long sentences"
      ],
      "metadata": {
        "id": "LbOcc8tk69GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def categorize_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    categorized = {\"short\": [], \"long\": []}\n",
        "\n",
        "    for sentence in sentences:\n",
        "        word_count = len(word_tokenize(sentence))\n",
        "        if word_count < 5:\n",
        "            categorized[\"short\"].append(sentence)\n",
        "        else:\n",
        "            categorized[\"long\"].append(sentence)\n",
        "\n",
        "    return categorized\n",
        "\n",
        "text = \"Hello! NLP is fun. Let's learn NLP together. It helps in many fields.\"\n",
        "categories = categorize_sentences(text)\n",
        "print(\"Short Sentences:\", categories[\"short\"])\n",
        "print(\"Long Sentences:\", categories[\"long\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IziFY8uY65fo",
        "outputId": "39dc9254-cf0a-49a5-951a-f15608ce310f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Short Sentences: ['Hello!', 'NLP is fun.']\n",
            "Long Sentences: [\"Let's learn NLP together.\", 'It helps in many fields.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP Task 2 - Rule based Sentiment Analysis"
      ],
      "metadata": {
        "id": "DPLqu1nv7CkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "positive_words = {\"happy\", \"good\", \"great\", \"excellent\", \"love\", \"amazing\"}\n",
        "negative_words = {\"sad\", \"bad\", \"terrible\", \"hate\", \"awful\", \"worst\"}\n",
        "\n",
        "def sentiment_analysis(text):\n",
        "    start_time = time.time()\n",
        "    words = text.lower().split()\n",
        "    pos_count = sum(1 for word in words if word in positive_words)\n",
        "    neg_count = sum(1 for word in words if word in negative_words)\n",
        "\n",
        "    sentiment = \"Positive Sentiment\" if pos_count > neg_count else \"Negative Sentiment\" if neg_count > pos_count else \"Neutral Sentiment\"\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    return sentiment, execution_time\n",
        "\n",
        "text = \"\"\"\n",
        "I'm happy you're the President, and thank you for bringing me home.\n",
        "I have never been so proud to be an American citizen. Thank you, Mr. President.\n",
        "\"\"\"\n",
        "sentiment, exec_time = sentiment_analysis(text)\n",
        "print(\"Sentiment:\", sentiment)\n",
        "print(\"Execution Time: {:.6f} seconds\".format(exec_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNSeNSNI6_pG",
        "outputId": "21bd33b5-4bd9-4890-b5fe-47b2e4296c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: Positive Sentiment\n",
            "Execution Time: 0.000016 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fbF4Z2hs7GG3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}